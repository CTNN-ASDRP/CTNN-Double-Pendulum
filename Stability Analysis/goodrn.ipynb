{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yY1Nwh0V0c"
      },
      "source": [
        "# Create pendelum data, (time, theta1, theta2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "s2Z7qdSm0Uvq",
        "outputId": "7b7cdf7d-f8ee-4594-93db-835e378d6519"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, pi\n",
        "from numpy import array, arange, zeros_like\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "g = 9.81\n",
        "L1 = 1\n",
        "L2 = 1\n",
        "m1 = 1.0\n",
        "m2 = 1.0\n",
        "\n",
        "def f(r, t, L1, L2):\n",
        "    theta1 = r[0]\n",
        "    omega1 = r[1]\n",
        "    theta2 = r[2]\n",
        "    omega2 = r[3]\n",
        "\n",
        "    ftheta1 = omega1\n",
        "    fomega1 = (-g * (2 * m1 + m2) * sin(theta1) - m2 * g * sin(theta1 - 2 * theta2) - 2 * sin(theta1 - theta2) * m2 *\n",
        "               (omega2**2 * L2 + omega1**2 * L1 * cos(theta1 - theta2))) / (L1 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    ftheta2 = omega2\n",
        "    fomega2 = (2 * sin(theta1 - theta2) * (omega1**2 * L1 * (m1 + m2) + g * (m1 + m2) * cos(theta1) + omega2**2 * L2 * m2 *\n",
        "                                           cos(theta1 - theta2))) / (L2 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    return array([ftheta1, fomega1, ftheta2, fomega2], float)\n",
        "\n",
        "a = 0.0\n",
        "b = 10\n",
        "N = 5000\n",
        "h = (b - a) / N\n",
        "\n",
        "angles = [[0, 0],[180, 180], [1, 0], [0, 1], [1, 1], [179, 180], [180, 179], [179, 179], [90, 90]]\n",
        "\n",
        "for x in angles:\n",
        "  tpoints = np.arange(a, b, h) # seconds, split into intervals of 100\n",
        "  theta1_points = np.zeros_like(tpoints) # what the first pendulm angle should be (empty)\n",
        "  theta2_points = np.zeros_like(tpoints) # what the second pendulm angle should be (empty)\n",
        "\n",
        "  q = np.array([x[0]*pi/180, 0, x[1]*pi/180, 0], float)\n",
        "\n",
        "  for i, t in enumerate(tpoints):\n",
        "      theta1_points[i] = q[0] * 180 / pi # converted from theta (θ) to degrees (°)\n",
        "      theta2_points[i] = q[2] * 180 / pi\n",
        "\n",
        "      k1 = h * f(q, t, L1, L2)\n",
        "      k2 = h * f(q + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "      k3 = h * f(q + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "      k4 = h * f(q + k3, t + h, L1, L2)\n",
        "      q += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "  plt.plot(tpoints, theta1_points, label='Theta1') # what the first pendulm is (populated)\n",
        "  plt.plot(tpoints, theta2_points, label='Theta2') # what the second pendulm is (populated)\n",
        "  plt.title(\"Double Pendulum\")\n",
        "  plt.xlabel(\"t (seconds)\")\n",
        "  plt.ylabel(\"degrees\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  data = np.stack((theta1_points, theta2_points), axis=1)\n",
        "  np.save(f'pendulum_data_{str(x[0])}_{str(x[1])}.npy', data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhOW_5BxvQtw"
      },
      "source": [
        "# Turn data into inputs and outputs and setup model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C3VtEYdvO_Y",
        "outputId": "cd51d20c-99b3-44d9-acc4-e849919e0f01"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define the dataset class\n",
        "class QuadraticDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32)  # Shape (N, 2)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)  # Shape (N, 2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "data = {}\n",
        "\n",
        "for i in angles:\n",
        "  loaded_data = np.load(f'pendulum_data_{str(i[0])}_{str(i[1])}.npy')\n",
        "  scaler = MinMaxScaler()\n",
        "  data_ = scaler.fit_transform(loaded_data)\n",
        "  data[f'{str(i[0])}_{str(i[1])}'] = data_\n",
        "\n",
        "print(data)\n",
        "\n",
        "\n",
        "def create_io(data):\n",
        "    x, x_1, x_2, y_1, y_2 = [], [], [], [], []\n",
        "    # for i in angles\n",
        "    for starting in data:\n",
        "      starting_theta_1_degrees = int(starting.split(\"_\")[0])\n",
        "      starting_theta_2_degrees = int(starting.split(\"_\")[1])\n",
        "\n",
        "      starting_theta_1 = starting_theta_1_degrees * pi /180\n",
        "      starting_theta_2 = starting_theta_2_degrees * pi /180\n",
        "\n",
        "      angle_data = data[starting]\n",
        "      for i in range(len(angle_data)):\n",
        "          x.append(tpoints[i])\n",
        "          x_1.append(starting_theta_1)\n",
        "          x_2.append(starting_theta_2)\n",
        "          y_1.append(angle_data[i][0])\n",
        "          y_2.append(angle_data[i][1])\n",
        "    return x, x_1, x_2, y_1, y_2\n",
        "\n",
        "x, x_1, x_2, y_1, y_2 = create_io(data)\n",
        "\n",
        "# Normalize data\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Combine x_1 and x_2 into one feature matrix\n",
        "x_combined = np.vstack([x_1, x_2, x]).T\n",
        "x_scaled = scaler_x.fit_transform(x_combined)\n",
        "\n",
        "# Combine y_1 and y_2 into one target matrix\n",
        "y_combined = np.vstack([y_1, y_2]).T\n",
        "y_scaled = scaler_y.fit_transform(y_combined)\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "dataset = QuadraticDataset(x_scaled, y_scaled)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "# Define the model class\n",
        "class ImprovedStackedRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(ImprovedStackedRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='relu')\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x should be (batch_size, sequence_length, input_size)\n",
        "        out, _ = self.rnn(x)\n",
        "        # out should be (batch_size, sequence_length, hidden_size)\n",
        "        out = self.fc(out[:, -1, :])  # Output from the final time step\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaMQoKbXvWh6"
      },
      "source": [
        "# Train le data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvwapOOTs5Ts",
        "outputId": "9dad2853-0261-4b32-c122-7ed89bf933b2"
      },
      "outputs": [],
      "source": [
        "# Create a new model instance\n",
        "input_size = 3  # Two input features\n",
        "hidden_size = 100\n",
        "output_size = 2  # Two output values\n",
        "num_layers = 5\n",
        "srnn = ImprovedStackedRNN(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Adam(srnn.parameters(), lr=0.001)\n",
        "\n",
        "early_stopping_patience = 10\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Training function with early stopping\n",
        "def train_model(model, train_loader, test_loader, num_epochs):\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for sequences, targets in train_loader:\n",
        "            sequences = sequences.unsqueeze(1)  # Add sequence dimension\n",
        "            targets = targets  # Target should be (batch_size, output_size)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(sequences)\n",
        "            loss = loss_function(y_pred, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences = sequences.unsqueeze(1)  # Add sequence dimension\n",
        "                targets = targets\n",
        "                y_pred = model(sequences)\n",
        "                loss = loss_function(y_pred, targets)\n",
        "                test_loss += loss.item()\n",
        "                all_preds.append(y_pred)\n",
        "                all_targets.append(targets)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "\n",
        "        # Flatten the lists and convert to numpy arrays\n",
        "        all_preds = torch.cat(all_preds).numpy()\n",
        "        all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "        r2 = r2_score(all_targets, all_preds, multioutput='uniform_average')\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}, R^2 Score: {r2}')\n",
        "\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            best_model = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    if best_model:\n",
        "        model.load_state_dict(best_model)\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "train_model(srnn, train_loader, test_loader, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XpwyXZOWoL3"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S10Qzm-3Wq7B",
        "outputId": "ce9279ac-2a96-4e7a-aa2b-5569a3442f10"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, targets in test_loader:\n",
        "            sequences = sequences.unsqueeze(1)  # Add sequence dimension\n",
        "            targets = targets\n",
        "            y_pred = model(sequences)\n",
        "            loss = loss_function(y_pred, targets)\n",
        "            test_loss += loss.item()\n",
        "            all_preds.append(y_pred)\n",
        "            all_targets.append(targets)\n",
        "\n",
        "    all_predictions = np.concatenate(all_preds, axis=0)\n",
        "    all_targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
        "    r2 = r2_score(all_targets, all_predictions)\n",
        "\n",
        "    print(f'Test RMSE: {rmse:.4f}')\n",
        "    print(f'R^2 Score: {r2:.4f}')\n",
        "evaluate_model(srnn, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na8wKN1AvYt5"
      },
      "source": [
        "# Plot predictions vs actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1zBCXLRRvSr",
        "outputId": "13c885d9-2152-4d5f-f50f-f08e9cc7c079"
      },
      "outputs": [],
      "source": [
        "deeta = {}\n",
        "for k in range(len(angles)):\n",
        "  i = angles[k]\n",
        "  deeta[f'{str(i[0])}_{str(i[1])}'] = {'x_1': x_1[:N*(k+1)], 'x_2': x_2[:N*(k+1)], 'y_1': y_1[:N*(k+1)], 'y_2': y_2[:N*(k+1)]}\n",
        "print(deeta)\n",
        "print(y_1[:5000])\n",
        "print(deeta[\"0_0\"][\"y_1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-bOAfQQxfu0H",
        "outputId": "8d80f117-4ae4-4e14-8d9d-0f8525ca5314"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for 90, 90\n",
        "\n",
        "angle_to_predict = \"0_0\"\n",
        "\n",
        "x_1_any = deeta[angle_to_predict][\"x_1\"]\n",
        "x_2_any = deeta[angle_to_predict][\"x_2\"]\n",
        "x_any = x[:N]\n",
        "y_1_any = deeta[angle_to_predict][\"y_1\"]\n",
        "y_2_any = deeta[angle_to_predict][\"y_2\"]\n",
        "\n",
        "x_dense_combined = np.vstack([x_1_any, x_2_any, x_any]).T\n",
        "x_dense_scaled = scaler_x.transform(x_dense_combined)\n",
        "x_dense_tensor = torch.tensor(x_dense_scaled, dtype=torch.float32).unsqueeze(1)  # Shape (500, 1, 2)\n",
        "\n",
        "srnn.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = srnn(x_dense_tensor).numpy()\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred_any = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# PLOTTING LOOKS A LITTLE OFF BECAUSE IT IS PLOTTING ALL ANGLES, NEEDS TO BE TURNED INTO NUMPY ARRAY AND SET TO NP.WHERE\n",
        "# x_1 = initial angle 1 and x_2 is initial angle\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_any, y_1_any, label='True y_1', color='blue', linestyle='--')\n",
        "plt.plot(x_any, y_2_any, label='True y_2', color='green', linestyle='--')\n",
        "plt.plot(x_any, y_pred_any[:, 0], label='Predicted y_1', color='red')\n",
        "plt.plot(x_any, y_pred_any[:, 1], label='Predicted y_2', color='orange')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Comparison of True and Predicted Quadratic Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qersz-j9hVj8"
      },
      "source": [
        "# Animate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V-gkyoF-uK2",
        "outputId": "c91d31a1-f66e-4284-c292-696399d10428"
      },
      "outputs": [],
      "source": [
        "y_pred_any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl818RdeB3aZ",
        "outputId": "4709064a-996e-4c23-c964-4342004fd84d"
      },
      "outputs": [],
      "source": [
        "from math import  floor\n",
        "floor((N/(b-a))/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1QWqmQJY0wq1",
        "outputId": "17d2d4d2-7e90-42a9-bf98-69feaceef4ef"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from math import sin, cos, pi, floor\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "def theta_to_xy(theta1, theta2, theta1Len=1, theta2len=1):\n",
        "    convert = pi/180\n",
        "    x1 = sin(theta1*convert) * theta1Len\n",
        "    y1 = -cos(theta1*convert) * theta1Len\n",
        "    x2 = x1 + sin(theta2*convert) * theta2len\n",
        "    y2 = y1 - cos(theta2*convert) * theta2len\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "x1_points = []\n",
        "y1_points = []\n",
        "x2_points = []\n",
        "y2_points = []\n",
        "\n",
        "x1_points_p = []\n",
        "y1_points_p = []\n",
        "x2_points_p = []\n",
        "y2_points_p = []\n",
        "\n",
        "fps = 30\n",
        "upframe = floor((N/(b-a))/30)\n",
        "\n",
        "for z in np.arange(0, N, upframe):\n",
        "    i = int(z)\n",
        "    preddy = scaler.inverse_transform(y_pred_any)\n",
        "    actual = scaler.inverse_transform(data[angle_to_predict])\n",
        "\n",
        "    x1, y1, x2, y2 = theta_to_xy(actual[i][0], actual[i][1])\n",
        "    x1_points.append(x1)\n",
        "    y1_points.append(y1)\n",
        "    x2_points.append(x2)\n",
        "    y2_points.append(y2)\n",
        "\n",
        "    t1 = preddy[i][0]\n",
        "    t2 = preddy[i][1]\n",
        "\n",
        "    x1p, y1p, x2p, y2p = theta_to_xy(t1, t2)\n",
        "    x1_points_p.append(x1p)\n",
        "    y1_points_p.append(y1p)\n",
        "    x2_points_p.append(x2p)\n",
        "    y2_points_p.append(y2p)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "L = 2\n",
        "ax = fig.add_subplot(autoscale_on=False, xlim=(-L, L), ylim=(-L, L))\n",
        "ax.set_aspect('equal')\n",
        "ax.grid()\n",
        "\n",
        "line, = ax.plot([], [], 'o-', lw=2)\n",
        "trace, = ax.plot([], [], 'r-', lw=1, ms=2, alpha=0.5)\n",
        "line_p, = ax.plot([], [], 'o-', lw=2)\n",
        "trace_p, = ax.plot([], [], 'r-', lw=1, ms=2, alpha=0.5)\n",
        "time_template = 'time = %.1fs'\n",
        "time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
        "\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    trace.set_data([], [])\n",
        "    line_p.set_data([], [])\n",
        "    trace_p.set_data([], [])\n",
        "    time_text.set_text('')\n",
        "    return line, trace, line_p, trace_p, time_text\n",
        "\n",
        "def update(i):\n",
        "    thisx = [0, x1_points[i], x2_points[i]]\n",
        "    thisy = [0, y1_points[i], y2_points[i]]\n",
        "\n",
        "    history_x = x2_points[:i]\n",
        "    history_y = y2_points[:i]\n",
        "\n",
        "    thisx_p = [0, x1_points_p[i], x2_points_p[i]]\n",
        "    thisy_p = [0, y1_points_p[i], y2_points_p[i]]\n",
        "\n",
        "    history_x_p = x2_points_p[:i]\n",
        "    history_y_p = y2_points_p[:i]\n",
        "\n",
        "    line.set_data(thisx, thisy)\n",
        "    trace.set_data(history_x, history_y)\n",
        "    line_p.set_data(thisx_p, thisy_p)\n",
        "    trace_p.set_data(history_x_p, history_y_p)\n",
        "    time_text.set_text(time_template % (a+((b-a)*(i / len(np.arange(0, N, upframe))))))\n",
        "    return line, trace, line_p, trace_p, time_text\n",
        "\n",
        "ani = FuncAnimation(fig, update, frames=len(np.arange(0, N, upframe)), init_func=init, blit=True, interval=fps)\n",
        "print(len(tpoints))\n",
        "print(tpoints)\n",
        "plt.close()\n",
        "ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OxcmVxTWYPG"
      },
      "source": [
        "# Plot predictions vs actual for unknown angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "qUlmOBmPWXSx",
        "outputId": "ecd2ae30-f90c-4eef-fe64-4c47b7765c8e"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for 85, 85\n",
        "angle = [0.1, 0.1]\n",
        "\n",
        "\n",
        "tpoints = np.arange(a, b, h) # seconds, split into intervals of 100\n",
        "theta1_points = np.zeros_like(tpoints) # what the first pendulm angle should be (empty)\n",
        "theta2_points = np.zeros_like(tpoints) # what the second pendulm angle should be (empty)\n",
        "\n",
        "q = np.array([angle[0]*pi/180, 0, angle[1]*pi/180, 0], float)\n",
        "\n",
        "for i, t in enumerate(tpoints):\n",
        "    theta1_points[i] = q[0] * 180 / pi # converted from theta (θ) to degrees (°)\n",
        "    theta2_points[i] = q[2] * 180 / pi\n",
        "\n",
        "    k1 = h * f(q, t, L1, L2)\n",
        "    k2 = h * f(q + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "    k3 = h * f(q + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "    k4 = h * f(q + k3, t + h, L1, L2)\n",
        "    q += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "x_1_unknown = [angle[0]*pi/180]*N\n",
        "x_2_unknown = [angle[1]*pi/180]*N\n",
        "x_unknown = tpoints.tolist()\n",
        "scaler = MinMaxScaler()\n",
        "y_1_2_unknown = scaler.fit_transform([[a, b] for a, b in zip(theta1_points, theta2_points)])\n",
        "y_1_unknown, y_2_unknown = map(list, zip(*y_1_2_unknown))\n",
        "\n",
        "x_dense_combined = np.vstack([x_1_unknown, x_2_unknown, x_unknown]).T\n",
        "x_dense_scaled = scaler_x.transform(x_dense_combined)\n",
        "x_dense_tensor = torch.tensor(x_dense_scaled, dtype=torch.float32).unsqueeze(1)  # Shape (500, 1, 2)\n",
        "\n",
        "srnn.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = srnn(x_dense_tensor).numpy()\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred_unknown = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# PLOTTING LOOKS A LITTLE OFF BECAUSE IT IS PLOTTING ALL ANGLES, NEEDS TO BE TURNED INTO NUMPY ARRAY AND SET TO NP.WHERE\n",
        "# x_1 = initial angle 1 and x_2 is initial angle\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_unknown, y_1_unknown, label='True y_1', color='blue', linestyle='--')\n",
        "plt.plot(x_unknown, y_2_unknown, label='True y_2', color='green', linestyle='--')\n",
        "plt.plot(x_unknown, y_pred_unknown[:, 0], label='Predicted y_1', color='red')\n",
        "plt.plot(x_unknown, y_pred_unknown[:, 1], label='Predicted y_2', color='orange')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Comparison of True and Predicted Quadratic Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chX7mZ6TcyIP"
      },
      "source": [
        "# Animate results for unknown angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "eSCoT3Gbcvgz",
        "outputId": "e880b764-1a9a-48db-f8e7-3ee59b9bfa16"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from math import sin, cos, pi, floor\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "def theta_to_xy(theta1, theta2, theta1Len=1, theta2len=1):\n",
        "    convert = pi/180\n",
        "    x1 = sin(theta1*convert) * theta1Len\n",
        "    y1 = -cos(theta1*convert) * theta1Len\n",
        "    x2 = x1 + sin(theta2*convert) * theta2len\n",
        "    y2 = y1 - cos(theta2*convert) * theta2len\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "x1_points = []\n",
        "y1_points = []\n",
        "x2_points = []\n",
        "y2_points = []\n",
        "\n",
        "x1_points_p = []\n",
        "y1_points_p = []\n",
        "x2_points_p = []\n",
        "y2_points_p = []\n",
        "\n",
        "fps = 30\n",
        "upframe = floor((N/(b-a))/30)\n",
        "\n",
        "for z in np.arange(0, N, upframe):\n",
        "    i = int(z)\n",
        "    preddy = scaler.inverse_transform(y_pred_unknown)\n",
        "    actual = scaler.inverse_transform(y_1_2_unknown)\n",
        "\n",
        "    x1, y1, x2, y2 = theta_to_xy(actual[i][0], actual[i][1])\n",
        "    x1_points.append(x1)\n",
        "    y1_points.append(y1)\n",
        "    x2_points.append(x2)\n",
        "    y2_points.append(y2)\n",
        "\n",
        "    t1 = preddy[i][0]\n",
        "    t2 = preddy[i][1]\n",
        "\n",
        "    x1p, y1p, x2p, y2p = theta_to_xy(t1, t2)\n",
        "    x1_points_p.append(x1p)\n",
        "    y1_points_p.append(y1p)\n",
        "    x2_points_p.append(x2p)\n",
        "    y2_points_p.append(y2p)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "L = 2\n",
        "ax = fig.add_subplot(autoscale_on=False, xlim=(-L, L), ylim=(-L, L))\n",
        "ax.set_aspect('equal')\n",
        "ax.grid()\n",
        "\n",
        "line, = ax.plot([], [], 'o-', lw=2)\n",
        "trace, = ax.plot([], [], 'r-', lw=1, ms=2, alpha=0.5)\n",
        "line_p, = ax.plot([], [], 'o-', lw=2)\n",
        "trace_p, = ax.plot([], [], 'r-', lw=1, ms=2, alpha=0.5)\n",
        "time_template = 'time = %.1fs'\n",
        "time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
        "\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    trace.set_data([], [])\n",
        "    line_p.set_data([], [])\n",
        "    trace_p.set_data([], [])\n",
        "    time_text.set_text('')\n",
        "    return line, trace, line_p, trace_p, time_text\n",
        "\n",
        "def update(i):\n",
        "    thisx = [0, x1_points[i], x2_points[i]]\n",
        "    thisy = [0, y1_points[i], y2_points[i]]\n",
        "\n",
        "    history_x = x2_points[:i]\n",
        "    history_y = y2_points[:i]\n",
        "\n",
        "    thisx_p = [0, x1_points_p[i], x2_points_p[i]]\n",
        "    thisy_p = [0, y1_points_p[i], y2_points_p[i]]\n",
        "\n",
        "    history_x_p = x2_points_p[:i]\n",
        "    history_y_p = y2_points_p[:i]\n",
        "\n",
        "    line.set_data(thisx, thisy)\n",
        "    trace.set_data(history_x, history_y)\n",
        "    line_p.set_data(thisx_p, thisy_p)\n",
        "    trace_p.set_data(history_x_p, history_y_p)\n",
        "    time_text.set_text(time_template % (i * h))\n",
        "    return line, trace, line_p, trace_p, time_text\n",
        "\n",
        "ani = FuncAnimation(fig, update, frames=len(np.arange(0, N, upframe)), init_func=init, blit=True, interval=fps)\n",
        "print(len(tpoints))\n",
        "print(tpoints)\n",
        "plt.close()\n",
        "ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlFr0QKZhR7G"
      },
      "source": [
        "# For testing specific angles (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr5bodKI24wl",
        "outputId": "0081959d-fcde-4c8c-9a7f-a6f8f84e794e"
      },
      "outputs": [],
      "source": [
        "# for testing specific angles\n",
        "\n",
        "srnn.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = srnn(torch.tensor(scaler_x.transform(np.vstack([pi/2, pi/2, 4]).T), dtype=torch.float32).unsqueeze(1)).numpy()\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_prediction_test = scaler_y.inverse_transform(y_pred_scaled)\n",
        "print(y_prediction_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stability Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "initial_conditions = np.arange(0, 181, 10)\n",
        "lyapunov_exponents = np.zeros((len(initial_conditions), len(initial_conditions)))\n",
        "\n",
        "def periodic_distance(theta1, theta2):\n",
        "    delta = (theta1 - theta2 + np.pi) % (2 * np.pi) - np.pi\n",
        "    return np.abs(delta)\n",
        "\n",
        "for i_1, angle_a_component in enumerate(initial_conditions):\n",
        "    for j_1, angle_b_component in enumerate(initial_conditions):\n",
        "\n",
        "        initial_condition = [angle_a_component, angle_b_component]\n",
        "        delta_0 = 1\n",
        "\n",
        "        angle_a = initial_condition\n",
        "        angle_b = [initial_condition[0] + delta_0, initial_condition[1] + delta_0]\n",
        "\n",
        "        tpoints = np.arange(a, b, h) # seconds, split into intervals of 100\n",
        "        theta1_points_a = np.zeros_like(tpoints) # what the first pendulm angle should be (empty)\n",
        "        theta2_points_a = np.zeros_like(tpoints) # what the second pendulm angle should be (empty)\n",
        "\n",
        "        theta1_points_b = np.zeros_like(tpoints)\n",
        "        theta2_points_b = np.zeros_like(tpoints)\n",
        "\n",
        "        q_a = np.array([angle_a[0]*pi/180, 0, angle_a[1]*pi/180, 0], float)\n",
        "        q_b = np.array([angle_b[0]*pi/180, 0, angle_b[1]*pi/180, 0], float)\n",
        "\n",
        "        for i, t in enumerate(tpoints):\n",
        "            theta1_points_a[i] = q_a[0] * 180 / pi # converted from theta (θ) to degrees (°)\n",
        "            theta2_points_a[i] = q_a[2] * 180 / pi\n",
        "\n",
        "            k1 = h * f(q_a, t, L1, L2)\n",
        "            k2 = h * f(q_a + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "            k3 = h * f(q_a + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "            k4 = h * f(q_a + k3, t + h, L1, L2)\n",
        "            q_a += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "            theta1_points_b[i] = q_b[0] * 180 / pi # converted from theta (θ) to degrees (°)\n",
        "            theta2_points_b[i] = q_b[2] * 180 / pi\n",
        "\n",
        "            k1 = h * f(q_b, t, L1, L2)\n",
        "            k2 = h * f(q_b + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "            k3 = h * f(q_b + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "            k4 = h * f(q_b + k3, t + h, L1, L2)\n",
        "            q_b += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "        x_1_unknown_a = [angle_a[0]*pi/180]*N\n",
        "        x_2_unknown_a = [angle_a[1]*pi/180]*N\n",
        "\n",
        "        x_1_unknown_b = [angle_b[0]*pi/180]*N\n",
        "        x_2_unknown_b = [angle_b[1]*pi/180]*N\n",
        "\n",
        "        x_unknown = tpoints.tolist()\n",
        "        scaler = MinMaxScaler()\n",
        "        y_1_2_unknown_a = scaler.fit_transform([[a, b] for a, b in zip(theta1_points_a, theta2_points_a)])\n",
        "        y_1_unknown_a, y_2_unknown_a = map(list, zip(*y_1_2_unknown_a))\n",
        "\n",
        "        y_1_2_unknown_b = scaler.fit_transform([[a, b] for a, b in zip(theta1_points_b, theta2_points_b)])\n",
        "        y_1_unknown_b, y_2_unknown_b = map(list, zip(*y_1_2_unknown_b))\n",
        "\n",
        "        x_dense_combined_a = np.vstack([x_1_unknown_a, x_2_unknown_a, x_unknown]).T\n",
        "        x_dense_scaled_a = scaler_x.transform(x_dense_combined_a)\n",
        "        x_dense_tensor_a = torch.tensor(x_dense_scaled_a, dtype=torch.float32).unsqueeze(1)  # Shape (500, 1, 2)\n",
        "\n",
        "        x_dense_combined_b = np.vstack([x_1_unknown_b, x_2_unknown_b, x_unknown]).T\n",
        "        x_dense_scaled_b = scaler_x.transform(x_dense_combined_b)\n",
        "        x_dense_tensor_b = torch.tensor(x_dense_scaled_b, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        srnn.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred_scaled_a = srnn(x_dense_tensor_a).numpy()\n",
        "            y_pred_scaled_b = srnn(x_dense_tensor_b).numpy()\n",
        "\n",
        "        # Inverse transform predictions\n",
        "        y_pred_unknown_a = scaler_y.inverse_transform(y_pred_scaled_a)\n",
        "        y_pred_unknown_b = scaler_y.inverse_transform(y_pred_scaled_b)\n",
        "\n",
        "        distances = []\n",
        "        for i in range(len(x_unknown)):\n",
        "            dist = math.sqrt(periodic_distance(y_pred_unknown_a[i, 0], y_pred_unknown_b[i, 0]) ** 2 + periodic_distance(y_pred_unknown_a[i, 1], y_pred_unknown_b[i, 1]) ** 2)\n",
        "            distances.append(math.log(abs(dist), math.e))\n",
        "\n",
        "        m, c = np.polyfit(np.arange(len(x_unknown)), distances, 1)\n",
        "\n",
        "        lyapunov_exponents[i_1][j_1] = m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Initial Conditions Leading to Negative Lyapunov Exponents:\")\n",
        "for i in range(lyapunov_exponents.shape[0]):\n",
        "    for j in range(lyapunov_exponents.shape[1]):\n",
        "        if lyapunov_exponents[i, j] < 0:\n",
        "            print(f\"Initial Conditions: θ1 = {initial_conditions[i]}°, θ2 = {initial_conditions[j]}°, Lyapunov Exponent: {lyapunov_exponents[i, j]}\")\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X, Y, lyapunov_exponents, cmap='viridis')\n",
        "\n",
        "z_plane = np.zeros_like(X)\n",
        "ax.plot_surface(X, Y, z_plane, color='red', alpha=0.5, rstride=100, cstride=100)\n",
        "\n",
        "ax.set_xlabel('Initial Angle A (degrees)')\n",
        "ax.set_ylabel('Initial Angle B (degrees)')\n",
        "ax.set_zlabel('Lyapunov Exponent')\n",
        "ax.set_title('Lyapunov Exponents for Different Initial Conditions')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
