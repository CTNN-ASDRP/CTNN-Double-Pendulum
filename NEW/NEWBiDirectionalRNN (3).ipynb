{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB5JpKoEkWO3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, pi\n",
        "from numpy import array, arange, zeros_like\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Double Pendulum Parameters\n",
        "g = 9.81\n",
        "L1 = 1\n",
        "L2 = 1\n",
        "m1 = 1.0\n",
        "m2 = 1.0\n",
        "\n",
        "# Function for Double Pendulum System\n",
        "def f(r, t, L1, L2):\n",
        "    theta1 = r[0]\n",
        "    omega1 = r[1]\n",
        "    theta2 = r[2]\n",
        "    omega2 = r[3]\n",
        "\n",
        "    ftheta1 = omega1\n",
        "    fomega1 = (-g * (2 * m1 + m2) * sin(theta1) - m2 * g * sin(theta1 - 2 * theta2) - 2 * sin(theta1 - theta2) * m2 *\n",
        "               (omega2**2 * L2 + omega1**2 * L1 * cos(theta1 - theta2))) / (L1 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    ftheta2 = omega2\n",
        "    fomega2 = (2 * sin(theta1 - theta2) * (omega1**2 * L1 * (m1 + m2) + g * (m1 + m2) * cos(theta1) + omega2**2 * L2 * m2 *\n",
        "                                           cos(theta1 - theta2))) / (L2 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    return array([ftheta1, fomega1, ftheta2, fomega2], float)\n",
        "\n",
        "# Simulation Parameters\n",
        "a = 0.0\n",
        "b = 10\n",
        "N = 2000\n",
        "h = (b - a) / N\n",
        "\n",
        "angles = [[120, 0], [121, 1], [120, 2], [120,4], [120,6], [120,8], [120,10],[122, 0], [122, 2], [122,4], [122,6], [122,8], [122,10],[124, 0], [124, 2], [124,4], [124,6], [124,8], [124,10], [126, 0], [126, 2], [126,4], [126,6], [126,8], [126,10], [128, 0], [128, 2], [128,4], [128,6], [128,8], [128,10], [130, 0], [130, 2], [130,4], [130,6], [130,8], [130,10]]\n",
        "\n",
        "for x in angles:\n",
        "    tpoints = np.arange(a, b, h)\n",
        "    theta1_points = np.zeros_like(tpoints)\n",
        "    theta2_points = np.zeros_like(tpoints)\n",
        "\n",
        "    q = np.array([x[0] * pi / 180, 0, x[1] * pi / 180, 0], float)\n",
        "\n",
        "    for i, t in enumerate(tpoints):\n",
        "        theta1_points[i] = q[0] * 180 / pi\n",
        "        theta2_points[i] = q[2] * 180 / pi\n",
        "\n",
        "        k1 = h * f(q, t, L1, L2)\n",
        "        k2 = h * f(q + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "        k3 = h * f(q + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "        k4 = h * f(q + k3, t + h, L1, L2)\n",
        "        q += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "    plt.plot(tpoints, theta1_points, label='Theta1')\n",
        "    plt.plot(tpoints, theta2_points, label='Theta2')\n",
        "    plt.title(\"Double Pendulum\")\n",
        "    plt.xlabel(\"t (seconds)\")\n",
        "    plt.ylabel(\"degrees\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    data = np.stack((theta1_points, theta2_points), axis=1)\n",
        "    np.save(f'pendulum_data_{str(x[0])}_{str(x[1])}.npy', data)\n",
        "\n",
        "\n",
        "# Check for CUDA availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the dataset class\n",
        "class QuadraticDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32).to(device)  # Shape (N, 3)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32).to(device)  # Shape (N, 2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "data = {}\n",
        "\n",
        "for i in angles:\n",
        "  loaded_data = np.load(f'pendulum_data_{str(i[0])}_{str(i[1])}.npy')\n",
        "  scaler = MinMaxScaler()\n",
        "  data_ = scaler.fit_transform(loaded_data)\n",
        "  data[f'{str(i[0])}_{str(i[1])}'] = data_\n",
        "\n",
        "print(data)\n",
        "\n",
        "def create_io(data):\n",
        "    x, x_1, x_2, y_1, y_2 = [], [], [], [], []\n",
        "    for starting in data:\n",
        "      starting_theta_1_degrees = int(starting.split(\"_\")[0])\n",
        "      starting_theta_2_degrees = int(starting.split(\"_\")[1])\n",
        "\n",
        "      starting_theta_1 = starting_theta_1_degrees * pi /180\n",
        "      starting_theta_2 = starting_theta_2_degrees * pi /180\n",
        "\n",
        "      angle_data = data[starting]\n",
        "      for i in range(len(angle_data)):\n",
        "          x.append(tpoints[i])\n",
        "          x_1.append(starting_theta_1)\n",
        "          x_2.append(starting_theta_2)\n",
        "          y_1.append(angle_data[i][0])\n",
        "          y_2.append(angle_data[i][1])\n",
        "    return x, x_1, x_2, y_1, y_2\n",
        "\n",
        "x, x_1, x_2, y_1, y_2 = create_io(data)\n",
        "\n",
        "# Normalize data\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "x_combined = np.vstack([x_1, x_2, x]).T\n",
        "x_scaled = scaler_x.fit_transform(x_combined)\n",
        "\n",
        "y_combined = np.vstack([y_1, y_2]).T\n",
        "y_scaled = scaler_y.fit_transform(y_combined)\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "dataset = QuadraticDataset(x_scaled, y_scaled)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "# Define the LSTM model class\n",
        "class BiRNNModel (nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(BiRNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                          bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])  # Output from the final time step\n",
        "        return out\n",
        "\n",
        "input_size = 3\n",
        "hidden_size = 100\n",
        "output_size = 2\n",
        "num_layers = 5\n",
        "bidirectionalmodel = BiRNNModel(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.MSELoss().to(device)\n",
        "optimizer = optim.Adam(bidirectionalmodel.parameters(), lr=0.001)\n",
        "\n",
        "early_stopping_patience = 10\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "\n",
        "# Training function with early stopping\n",
        "def train_model(model, train_loader, test_loader, num_epochs):\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model = None\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for sequences, targets in train_loader:\n",
        "            sequences, targets = sequences.to(device), targets.to(device)\n",
        "            sequences = sequences.unsqueeze(1)  # Add sequence dimension\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(sequences)\n",
        "            loss = loss_function(y_pred, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences, targets = sequences.to(device), targets.to(device)\n",
        "                sequences = sequences.unsqueeze(1)  # Add sequence dimension\n",
        "                y_pred = model(sequences)\n",
        "                loss = loss_function(y_pred, targets)\n",
        "                test_loss += loss.item()\n",
        "                all_preds.append(y_pred.cpu())\n",
        "                all_targets.append(targets.cpu())\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        val_losses.append(test_loss)\n",
        "\n",
        "        all_preds = torch.cat(all_preds).numpy()\n",
        "        all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "        r2 = r2_score(all_targets, all_preds, multioutput='uniform_average')\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}, R^2 Score: {r2}')\n",
        "\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            best_model = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    if best_model:\n",
        "        model.load_state_dict(best_model)\n",
        "        torch.save(bidirectionalmodel.state_dict(), 'lstm_model.pth')\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Training the model\n",
        "NUM_EPOCHS = 100\n",
        "train_losses, val_losses = train_model(bidirectionalmodel, train_loader, test_loader, NUM_EPOCHS)\n",
        "\n",
        "# Generate predictions for 120,0\n",
        "x_dense_combined = np.vstack([x_1[2000:4000], x_2[2000:4000], x[2000:4000]]).T\n",
        "x_dense_scaled = scaler_x.transform(x_dense_combined)\n",
        "x_dense_tensor = torch.tensor(x_dense_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "bidirectionalmodel.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = bidirectionalmodel(x_dense_tensor).cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred_90_90 = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# RMSE and R^2 scores\n",
        "rmse = np.sqrt(mean_squared_error(y_combined[2000:4000], y_pred_90_90))\n",
        "r2 = r2_score(y_combined[2000:4000], y_pred_90_90)\n",
        "print(f\"Final RMSE: {rmse}\")\n",
        "print(f\"Final R^2 Score: {r2}\")\n",
        "\n",
        "# Plotting results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x[2000:4000], y_1[2000:4000], label='True y_1', color='blue', linestyle='--')\n",
        "plt.plot(x[2000:4000], y_2[2000:4000], label='True y_2', color='green', linestyle='--')\n",
        "plt.plot(x[2000:4000], y_pred_90_90[:, 0], label='Predicted y_1', color='red')\n",
        "plt.plot(x[2000:4000], y_pred_90_90[:, 1], label='Predicted y_2', color='orange')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Angle (degrees)')\n",
        "plt.title('Comparison of True and Predicted Angles for Double Pendulum')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training vs validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, pi\n",
        "from numpy import array, arange, zeros_like\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Double Pendulum Parameters\n",
        "g = 9.81\n",
        "L1 = 1\n",
        "L2 = 1\n",
        "m1 = 1.0\n",
        "m2 = 1.0\n",
        "\n",
        "# Function for Double Pendulum System\n",
        "def f(r, t, L1, L2):\n",
        "    theta1 = r[0]\n",
        "    omega1 = r[1]\n",
        "    theta2 = r[2]\n",
        "    omega2 = r[3]\n",
        "\n",
        "    ftheta1 = omega1\n",
        "    fomega1 = (-g * (2 * m1 + m2) * sin(theta1) - m2 * g * sin(theta1 - 2 * theta2) - 2 * sin(theta1 - theta2) * m2 *\n",
        "               (omega2**2 * L2 + omega1**2 * L1 * cos(theta1 - theta2))) / (L1 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    ftheta2 = omega2\n",
        "    fomega2 = (2 * sin(theta1 - theta2) * (omega1**2 * L1 * (m1 + m2) + g * (m1 + m2) * cos(theta1) + omega2**2 * L2 * m2 *\n",
        "                                           cos(theta1 - theta2))) / (L2 * (2 * m1 + m2 - m2 * cos(2 * theta1 - 2 * theta2)))\n",
        "\n",
        "    return array([ftheta1, fomega1, ftheta2, fomega2], float)\n",
        "\n",
        "# Simulation Parameters\n",
        "a = 0.0\n",
        "b = 10\n",
        "N = 2000\n",
        "h = (b - a) / N\n",
        "\n",
        "angles = [[121, 1]]\n",
        "\n",
        "for x in angles:\n",
        "    tpoints = np.arange(a, b, h)\n",
        "    theta1_points = np.zeros_like(tpoints)\n",
        "    theta2_points = np.zeros_like(tpoints)\n",
        "\n",
        "    q = np.array([x[0] * pi / 180, 0, x[1] * pi / 180, 0], float)\n",
        "\n",
        "    for i, t in enumerate(tpoints):\n",
        "        theta1_points[i] = q[0] * 180 / pi\n",
        "        theta2_points[i] = q[2] * 180 / pi\n",
        "\n",
        "        k1 = h * f(q, t, L1, L2)\n",
        "        k2 = h * f(q + 0.5 * k1, t + 0.5 * h, L1, L2)\n",
        "        k3 = h * f(q + 0.5 * k2, t + 0.5 * h, L1, L2)\n",
        "        k4 = h * f(q + k3, t + h, L1, L2)\n",
        "        q += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "    plt.plot(tpoints, theta1_points, label='Theta1')\n",
        "    plt.plot(tpoints, theta2_points, label='Theta2')\n",
        "    plt.title(\"Double Pendulum\")\n",
        "    plt.xlabel(\"t (seconds)\")\n",
        "    plt.ylabel(\"degrees\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    data = np.stack((theta1_points, theta2_points), axis=1)\n",
        "    np.save(f'pendulum_data_{str(x[0])}_{str(x[1])}.npy', data)\n",
        "\n",
        "# Check for CUDA availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the dataset class\n",
        "class QuadraticDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32).to(device)  # Shape (N, 3)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32).to(device)  # Shape (N, 2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "data = {}\n",
        "\n",
        "for i in angles:\n",
        "  loaded_data = np.load(f'pendulum_data_{str(i[0])}_{str(i[1])}.npy')\n",
        "  scaler = MinMaxScaler()\n",
        "  data_ = scaler.fit_transform(loaded_data)\n",
        "  data[f'{str(i[0])}_{str(i[1])}'] = data_\n",
        "\n",
        "print(data)\n",
        "\n",
        "def create_io(data):\n",
        "    x, x_1, x_2, y_1, y_2 = [], [], [], [], []\n",
        "    for starting in data:\n",
        "      starting_theta_1_degrees = int(starting.split(\"_\")[0])\n",
        "      starting_theta_2_degrees = int(starting.split(\"_\")[1])\n",
        "\n",
        "      starting_theta_1 = starting_theta_1_degrees * pi /180\n",
        "      starting_theta_2 = starting_theta_2_degrees * pi /180\n",
        "\n",
        "      angle_data = data[starting]\n",
        "      for i in range(len(angle_data)):\n",
        "          x.append(tpoints[i])\n",
        "          x_1.append(starting_theta_1)\n",
        "          x_2.append(starting_theta_2)\n",
        "          y_1.append(angle_data[i][0])\n",
        "          y_2.append(angle_data[i][1])\n",
        "    return x, x_1, x_2, y_1, y_2\n",
        "\n",
        "x, x_1, x_2, y_1, y_2 = create_io(data)\n",
        "\n",
        "# Normalize data\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "x_combined = np.vstack([x_1, x_2, x]).T\n",
        "x_scaled = scaler_x.fit_transform(x_combined)\n",
        "\n",
        "y_combined = np.vstack([y_1, y_2]).T\n",
        "y_scaled = scaler_y.fit_transform(y_combined)\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "dataset = QuadraticDataset(x_scaled, y_scaled)\n",
        "\n",
        "test_loader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "x_dense_combined = np.vstack([x_1, x_2, x]).T\n",
        "x_dense_scaled = scaler_x.transform(x_dense_combined)\n",
        "x_dense_tensor = torch.tensor(x_dense_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "lstm_model.load_state_dict(torch.load('lstm_model.pth'))\n",
        "lstm_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = bidirectionalmodel(x_dense_tensor).cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred_90_90 = scaler_y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# RMSE and R^2 scores\n",
        "rmse = np.sqrt(mean_squared_error(y_combined, y_pred_90_90))\n",
        "r2 = r2_score(y_combined, y_pred_90_90)\n",
        "print(f\"Final RMSE: {rmse}\")\n",
        "print(f\"Final R^2 Score: {r2}\")\n",
        "\n",
        "# Plotting results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x, y_1, label='True y_1', color='blue', linestyle='--')\n",
        "plt.plot(x, y_2, label='True y_2', color='green', linestyle='--')\n",
        "plt.plot(x, y_pred_90_90[:, 0], label='Predicted y_1', color='red')\n",
        "plt.plot(x, y_pred_90_90[:, 1], label='Predicted y_2', color='orange')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Angle (degrees)')\n",
        "plt.title('Comparison of True and Predicted Angles for Double Pendulum')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training vs validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YMTyYzRHkY2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}